@article { Chatfield2014a,
	abstract = {The latest generation of Convolutional Neural Networks (CNN) have achieved
impressive results in challenging benchmarks on image recognition and object
detection, significantly raising the interest of the community in these
methods. Nevertheless, it is still unclear how different CNN methods compare
with each other and with previous state-of-the-art shallow representations such
as the Bag-of-Visual-Words and the Improved Fisher Vector. This paper conducts
a rigorous evaluation of these new techniques, exploring different deep
architectures and comparing them on a common ground, identifying and disclosing
important implementation details. We identify several useful properties of
CNN-based representations, including the fact that the dimensionality of the
CNN output layer can be reduced significantly without having an adverse effect
on performance. We also identify aspects of deep and shallow methods that can
be successfully shared. In particular, we show that the data augmentation
techniques commonly applied to CNN-based methods can also be applied to shallow
methods, and result in an analogous performance boost. Source code and models
to reproduce the experiments in the paper is made publicly available.},
	url = {http://arxiv.org/pdf/1405.3531v4},
	eprint = {1405.3531},
	arxivid = {1405.3531},
	archiveprefix = {arXiv},
	month = {May},
	year = {2014},
	booktitle = {arXiv},
	title = {Return of the Devil in the Details: Delving Deep into Convolutional Nets},
	author = {Ken Chatfield and Karen Simonyan and Andrea Vedaldi and Andrew Zisserman}
}

