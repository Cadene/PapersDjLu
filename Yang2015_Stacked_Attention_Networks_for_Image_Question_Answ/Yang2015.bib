@article { Yang2015,
	abstract = {This paper presents stacked attention networks (SANs) that learn to answer
natural language questions from images. SANs use semantic representation of a
question as query to search for the regions in an image that are related to the
answer. We argue that image question answering (QA) often requires multiple
steps of reasoning. Thus, we develop a multiple-layer SAN in which we query an
image multiple times to infer the answer progressively. Experiments conducted
on four image QA data sets demonstrate that the proposed SANs significantly
outperform previous state-of-the-art approaches. The visualization of the
attention layers illustrates the progress that the SAN locates the relevant
visual clues that lead to the answer of the question layer-by-layer.},
	url = {http://arxiv.org/pdf/1511.02274v2},
	eprint = {1511.02274},
	arxivid = {1511.02274},
	archiveprefix = {arXiv},
	month = {Nov},
	year = {2015},
	booktitle = {arXiv},
	title = {Stacked Attention Networks for Image Question Answering},
	author = {Zichao Yang and Xiaodong He and Jianfeng Gao and Li Deng and Alex Smola}
}

