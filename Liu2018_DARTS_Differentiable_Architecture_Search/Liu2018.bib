@article { Liu2018,
	abstract = {This paper addresses the scalability challenge of architecture search by
formulating the task in a differentiable manner. Unlike conventional approaches
of applying evolution or reinforcement learning over a discrete and
non-differentiable search space, our method is based on the continuous
relaxation of the architecture representation, allowing efficient search of the
architecture using gradient descent. Extensive experiments on CIFAR-10,
ImageNet, Penn Treebank and WikiText-2 show that our algorithm excels in
discovering high-performance convolutional architectures for image
classification and recurrent architectures for language modeling, while being
orders of magnitude faster than state-of-the-art non-differentiable techniques.},
	url = {http://arxiv.org/pdf/1806.09055v1},
	eprint = {1806.09055},
	arxivid = {1806.09055},
	archiveprefix = {arXiv},
	month = {Jun},
	year = {2018},
	booktitle = {arXiv},
	title = {{DARTS: Differentiable Architecture Search}},
	author = {Hanxiao Liu and Karen Simonyan and Yiming Yang}
}

