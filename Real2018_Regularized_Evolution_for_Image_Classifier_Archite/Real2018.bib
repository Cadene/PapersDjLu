@article { Real2018,
	abstract = {The effort devoted to hand-crafting image classifiers has motivated the use
of architecture search to discover them automatically. Reinforcement learning
and evolution have both shown promise for this purpose. This study employs a
regularized version of a popular asynchronous evolutionary algorithm. We
rigorously compare it to the non-regularized form and to a highly-successful
reinforcement learning baseline. Using the same hardware, compute effort and
neural network training code, we conduct repeated experiments side-by-side,
exploring different datasets, search spaces and scales. We show regularized
evolution consistently produces models with similar or higher accuracy, across
a variety of contexts without need for re-tuning parameters. In addition,
evolution exhibits considerably better performance than reinforcement learning
at early search stages, suggesting it may be the better choice when fewer
compute resources are available. This constitutes the first controlled
comparison of the two search algorithms in this context. Finally, we present
new architectures discovered with evolution that we nickname AmoebaNets. These
models achieve state-of-the-art results for CIFAR-10 (mean test error = 2.13%),
mobile-size ImageNet (top-1 accuracy = 75.1% with 5.1 M parameters) and
ImageNet (top-1 accuracy = 83.1%). This is the first time evolutionary
algorithms produce state-of-the-art image classifiers.},
	url = {http://arxiv.org/pdf/1802.01548v3},
	eprint = {1802.01548},
	arxivid = {1802.01548},
	archiveprefix = {arXiv},
	month = {Feb},
	year = {2018},
	booktitle = {arXiv},
	title = {{Regularized Evolution for Image Classifier Architecture Search}},
	author = {Esteban Real and Alok Aggarwal and Yanping Huang and Quoc V Le}
}

