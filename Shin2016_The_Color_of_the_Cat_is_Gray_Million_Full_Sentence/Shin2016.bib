@article { Shin2016,
	abstract = {Visual Question Answering (VQA) task has showcased a new stage of interaction
between language and vision, two of the most pivotal components of artificial
intelligence. However, it has mostly focused on generating short and repetitive
answers, mostly single words, which fall short of rich linguistic capabilities
of humans. We introduce Full-Sentence Visual Question Answering (FSVQA)
dataset, consisting of nearly 1 million pairs of questions and full-sentence
answers for images, built by applying a number of rule-based natural language
processing techniques to original VQA dataset and captions in the MS COCO
dataset. This poses many additional complexities to conventional VQA task, and
we provide a baseline for approaching and evaluating the task, on top of which
we invite the research community to build further improvements.},
	url = {http://arxiv.org/pdf/1609.06657v1},
	eprint = {1609.06657},
	arxivid = {1609.06657},
	archiveprefix = {arXiv},
	month = {Sep},
	year = {2016},
	booktitle = {arXiv},
	title = {The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question
  Answering (FSVQA)},
	author = {Andrew Shin and Yoshitaka Ushiku and Tatsuya Harada}
}

